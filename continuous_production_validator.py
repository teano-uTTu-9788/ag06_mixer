#!/usr/bin/env python3
"""
Continuous Production Validator
Automated validation and optimization of production systems following Google SRE practices
"""

import asyncio
import json
import time
import requests
import psutil
from datetime import datetime, timedelta
from typing import Dict, List, Any, Optional
from dataclasses import dataclass, asdict
from pathlib import Path
import logging

# Import production components
from integrated_workflow_system import IntegratedWorkflowSystem
from automated_backup_recovery_system import AutomatedBackupRecoverySystem
from performance_optimization_monitoring import PerformanceOptimizationMonitor
from production_logging_audit_system import ProductionLoggingSystem, LogLevel, AuditEventType

@dataclass
class ValidationResult:
    component: str
    test_name: str
    status: str  # PASS, FAIL, WARNING
    score: float
    details: str
    timestamp: datetime
    execution_time_ms: float
    recommendations: List[str]

@dataclass
class SystemHealthScore:
    overall_score: float
    availability_score: float
    performance_score: float
    reliability_score: float
    security_score: float
    compliance_score: float
    timestamp: datetime
    trend: str  # IMPROVING, STABLE, DEGRADING

class ContinuousProductionValidator:
    """Continuous validation system for production environment"""
    
    def __init__(self):
        self.validation_results: List[ValidationResult] = []
        self.health_history: List[SystemHealthScore] = []
        self.system = None
        self.backup_system = None
        self.performance_monitor = None
        self.logging_system = ProductionLoggingSystem()
        self.validation_active = True
        
        # Validation thresholds (Google SRE standards)
        self.thresholds = {
            'availability_minimum': 99.9,      # 99.9% uptime
            'response_time_p99_ms': 5000,      # 99th percentile < 5s
            'error_rate_maximum': 0.1,         # < 0.1% error rate
            'backup_success_rate': 100.0,      # 100% backup success
            'security_score_minimum': 95.0,    # 95% security compliance
            'performance_score_minimum': 85.0  # 85% performance score
        }
        
        # Setup logging
        logging.basicConfig(level=logging.INFO, format='%(asctime)s | %(levelname)s | %(message)s')
        self.logger = logging.getLogger(__name__)
    
    async def initialize(self):
        """Initialize continuous validation system"""
        self.logger.info("üîß Initializing Continuous Production Validator...")
        
        # Initialize core systems
        self.system = IntegratedWorkflowSystem()
        self.backup_system = AutomatedBackupRecoverySystem()
        await self.backup_system.initialize()
        
        self.performance_monitor = PerformanceOptimizationMonitor()
        await self.performance_monitor.initialize()
        
        # Start continuous validation loop
        asyncio.create_task(self._continuous_validation_loop())
        
        self.logger.info("‚úÖ Continuous Production Validator initialized")
        return True
    
    async def execute_production_validation(self) -> List[ValidationResult]:
        """Execute comprehensive production validation suite"""
        validation_results = []
        start_time = time.time()
        
        self.logger.info("üîÑ Executing production validation suite...")
        
        # 1. System Health Validation
        health_result = await self._validate_system_health()
        validation_results.append(health_result)
        
        # 2. Performance Validation
        performance_result = await self._validate_performance_metrics()
        validation_results.append(performance_result)
        
        # 3. Backup System Validation
        backup_result = await self._validate_backup_system()
        validation_results.append(backup_result)
        
        # 4. Dashboard Availability Validation
        dashboard_result = await self._validate_dashboard_availability()
        validation_results.append(dashboard_result)
        
        # 5. Security & Compliance Validation
        security_result = await self._validate_security_compliance()
        validation_results.append(security_result)
        
        # 6. Workflow Engine Validation
        workflow_result = await self._validate_workflow_engine()
        validation_results.append(workflow_result)
        
        # 7. Alert System Validation
        alerts_result = await self._validate_alert_system()
        validation_results.append(alerts_result)
        
        # 8. Data Integrity Validation
        integrity_result = await self._validate_data_integrity()
        validation_results.append(integrity_result)
        
        # Store results
        self.validation_results.extend(validation_results)
        
        # Calculate overall health score
        health_score = await self._calculate_system_health_score(validation_results)
        self.health_history.append(health_score)
        
        total_time = (time.time() - start_time) * 1000
        self.logger.info(f"‚úÖ Production validation completed in {total_time:.1f}ms - Overall Score: {health_score.overall_score:.1f}%")
        
        # Audit validation execution
        self.logging_system.audit(
            AuditEventType.SYSTEM_EVENT,
            "production_validation_executed",
            "validation_system",
            outcome="SUCCESS",
            metadata={
                'total_tests': len(validation_results),
                'overall_score': health_score.overall_score,
                'execution_time_ms': total_time
            }
        )
        
        return validation_results
    
    async def _validate_system_health(self) -> ValidationResult:
        """Validate core system health"""
        start_time = time.time()
        
        try:
            # Get system health
            health_data = await self.system.get_system_health()
            
            # Check system status
            status = health_data.get('status', 'unknown')
            score = float(health_data.get('score', 0))
            
            if status == 'healthy' and score >= 90:
                result_status = 'PASS'
                details = f"System healthy with score {score:.1f}%"
                recommendations = []
            elif score >= 70:
                result_status = 'WARNING' 
                details = f"System functional but score {score:.1f}% below optimal"
                recommendations = ["Monitor system resources", "Check for performance bottlenecks"]
            else:
                result_status = 'FAIL'
                details = f"System unhealthy with score {score:.1f}%"
                recommendations = ["Investigate system issues", "Check error logs", "Consider restart"]
            
            execution_time = (time.time() - start_time) * 1000
            
            return ValidationResult(
                component="system_health",
                test_name="core_system_health_check",
                status=result_status,
                score=score,
                details=details,
                timestamp=datetime.utcnow(),
                execution_time_ms=execution_time,
                recommendations=recommendations
            )
            
        except Exception as e:
            execution_time = (time.time() - start_time) * 1000
            return ValidationResult(
                component="system_health",
                test_name="core_system_health_check",
                status='FAIL',
                score=0.0,
                details=f"Health check failed: {str(e)}",
                timestamp=datetime.utcnow(),
                execution_time_ms=execution_time,
                recommendations=["Check system connectivity", "Verify system initialization"]
            )
    
    async def _validate_performance_metrics(self) -> ValidationResult:
        """Validate performance metrics against SRE standards"""
        start_time = time.time()
        
        try:
            # Get performance monitoring status
            perf_status = await self.performance_monitor.get_performance_monitoring_status()
            
            # Analyze metrics
            total_metrics = perf_status['metrics']['total_collected']
            anomaly_count = perf_status['metrics']['recent_anomalies']
            monitored_components = perf_status['metrics']['monitored_components']
            
            # Calculate score based on metrics collection and anomalies
            base_score = 100.0
            if total_metrics < 10:
                base_score -= 30  # Insufficient data collection
            if anomaly_count > 5:
                base_score -= (anomaly_count - 5) * 10  # Deduct for excessive anomalies
            
            score = max(0, min(100, base_score))
            
            if score >= self.thresholds['performance_score_minimum']:
                result_status = 'PASS'
                details = f"Performance monitoring healthy - {total_metrics} metrics, {anomaly_count} anomalies"
                recommendations = []
            elif score >= 70:
                result_status = 'WARNING'
                details = f"Performance issues detected - {anomaly_count} anomalies in {total_metrics} metrics"
                recommendations = ["Review performance anomalies", "Check resource utilization"]
            else:
                result_status = 'FAIL'
                details = f"Critical performance issues - Score {score:.1f}%"
                recommendations = ["Immediate performance investigation required", "Check system resources"]
            
            execution_time = (time.time() - start_time) * 1000
            
            return ValidationResult(
                component="performance_monitoring",
                test_name="performance_metrics_validation",
                status=result_status,
                score=score,
                details=details,
                timestamp=datetime.utcnow(),
                execution_time_ms=execution_time,
                recommendations=recommendations
            )
            
        except Exception as e:
            execution_time = (time.time() - start_time) * 1000
            return ValidationResult(
                component="performance_monitoring", 
                test_name="performance_metrics_validation",
                status='FAIL',
                score=0.0,
                details=f"Performance validation failed: {str(e)}",
                timestamp=datetime.utcnow(),
                execution_time_ms=execution_time,
                recommendations=["Check performance monitoring system"]
            )
    
    async def _validate_backup_system(self) -> ValidationResult:
        """Validate backup system functionality"""
        start_time = time.time()
        
        try:
            # Get backup system status
            backup_status = await self.backup_system.get_backup_status()
            
            success_rate = backup_status['success_rate']
            total_backups = backup_status['total_backups']
            failed_backups = backup_status['failed_backups']
            
            if success_rate >= self.thresholds['backup_success_rate']:
                result_status = 'PASS'
                details = f"Backup system healthy - {success_rate:.1f}% success rate ({total_backups} total)"
                recommendations = []
            elif success_rate >= 95:
                result_status = 'WARNING'
                details = f"Backup issues detected - {success_rate:.1f}% success, {failed_backups} failures"
                recommendations = ["Review failed backups", "Check backup storage"]
            else:
                result_status = 'FAIL'
                details = f"Critical backup failures - {success_rate:.1f}% success rate"
                recommendations = ["Immediate backup system investigation", "Check storage availability"]
            
            execution_time = (time.time() - start_time) * 1000
            
            return ValidationResult(
                component="backup_system",
                test_name="backup_system_validation",
                status=result_status,
                score=success_rate,
                details=details,
                timestamp=datetime.utcnow(),
                execution_time_ms=execution_time,
                recommendations=recommendations
            )
            
        except Exception as e:
            execution_time = (time.time() - start_time) * 1000
            return ValidationResult(
                component="backup_system",
                test_name="backup_system_validation", 
                status='FAIL',
                score=0.0,
                details=f"Backup validation failed: {str(e)}",
                timestamp=datetime.utcnow(),
                execution_time_ms=execution_time,
                recommendations=["Check backup system connectivity"]
            )
    
    async def _validate_dashboard_availability(self) -> ValidationResult:
        """Validate production dashboard availability"""
        start_time = time.time()
        
        try:
            # Test dashboard endpoints
            base_url = "http://localhost:8080"
            endpoints = ["/health", "/metrics"]
            
            successful_endpoints = 0
            total_endpoints = len(endpoints)
            
            for endpoint in endpoints:
                try:
                    response = requests.get(f"{base_url}{endpoint}", timeout=5)
                    if response.status_code in [200, 404]:  # 404 is acceptable for some endpoints
                        successful_endpoints += 1
                except:
                    pass
            
            availability_score = (successful_endpoints / total_endpoints) * 100
            
            if availability_score >= 90:
                result_status = 'PASS'
                details = f"Dashboard available - {successful_endpoints}/{total_endpoints} endpoints responsive"
                recommendations = []
            elif availability_score >= 50:
                result_status = 'WARNING'
                details = f"Partial dashboard availability - {successful_endpoints}/{total_endpoints} endpoints"
                recommendations = ["Check dashboard service status", "Verify network connectivity"]
            else:
                result_status = 'FAIL'
                details = f"Dashboard unavailable - {successful_endpoints}/{total_endpoints} endpoints responsive"
                recommendations = ["Restart dashboard service", "Check port availability"]
            
            execution_time = (time.time() - start_time) * 1000
            
            return ValidationResult(
                component="production_dashboard",
                test_name="dashboard_availability_check",
                status=result_status,
                score=availability_score,
                details=details,
                timestamp=datetime.utcnow(),
                execution_time_ms=execution_time,
                recommendations=recommendations
            )
            
        except Exception as e:
            execution_time = (time.time() - start_time) * 1000
            return ValidationResult(
                component="production_dashboard",
                test_name="dashboard_availability_check",
                status='FAIL', 
                score=0.0,
                details=f"Dashboard validation failed: {str(e)}",
                timestamp=datetime.utcnow(),
                execution_time_ms=execution_time,
                recommendations=["Check dashboard service"]
            )
    
    async def _validate_security_compliance(self) -> ValidationResult:
        """Validate security and compliance systems"""
        start_time = time.time()
        
        try:
            # Get logging system status
            logging_status = await self.logging_system.get_logging_system_status()
            
            # Check compliance features
            audit_enabled = logging_status['audit']['enabled']
            security_features = logging_status['security']
            
            score = 0.0
            if audit_enabled:
                score += 40
            if security_features['log_sanitization']:
                score += 20
            if security_features['pii_detection']:
                score += 20
            if security_features['integrity_verification']:
                score += 20
            
            if score >= self.thresholds['security_score_minimum']:
                result_status = 'PASS'
                details = f"Security compliance healthy - {score:.1f}% compliance"
                recommendations = []
            elif score >= 80:
                result_status = 'WARNING'
                details = f"Security compliance acceptable - {score:.1f}%"
                recommendations = ["Enable missing security features", "Review compliance settings"]
            else:
                result_status = 'FAIL'
                details = f"Security compliance insufficient - {score:.1f}%"
                recommendations = ["Enable audit logging", "Implement security features"]
            
            execution_time = (time.time() - start_time) * 1000
            
            return ValidationResult(
                component="security_compliance",
                test_name="security_compliance_check",
                status=result_status,
                score=score,
                details=details,
                timestamp=datetime.utcnow(),
                execution_time_ms=execution_time,
                recommendations=recommendations
            )
            
        except Exception as e:
            execution_time = (time.time() - start_time) * 1000
            return ValidationResult(
                component="security_compliance",
                test_name="security_compliance_check",
                status='FAIL',
                score=0.0,
                details=f"Security validation failed: {str(e)}",
                timestamp=datetime.utcnow(),
                execution_time_ms=execution_time,
                recommendations=["Check logging system"]
            )
    
    async def _validate_workflow_engine(self) -> ValidationResult:
        """Validate workflow engine functionality"""
        start_time = time.time()
        
        try:
            # Execute test workflow
            test_result = await self.system.execute_workflow(
                "validation_test",
                "validation",
                ["initialize", "validate", "complete"],
                {"validation": True, "test_id": f"val_{int(time.time())}"}
            )
            
            if test_result.get('status') == 'success':
                duration_ms = test_result.get('total_duration_ms', 0)
                
                if duration_ms < self.thresholds['response_time_p99_ms']:
                    result_status = 'PASS'
                    details = f"Workflow engine healthy - Test completed in {duration_ms:.1f}ms"
                    recommendations = []
                    score = 100.0
                else:
                    result_status = 'WARNING'
                    details = f"Workflow engine slow - Test took {duration_ms:.1f}ms"
                    recommendations = ["Check workflow performance", "Review system resources"]
                    score = 75.0
            else:
                result_status = 'FAIL'
                details = f"Workflow execution failed - {test_result.get('error', 'Unknown error')}"
                recommendations = ["Check workflow engine", "Review system logs"]
                score = 0.0
            
            execution_time = (time.time() - start_time) * 1000
            
            return ValidationResult(
                component="workflow_engine",
                test_name="workflow_execution_test",
                status=result_status,
                score=score,
                details=details,
                timestamp=datetime.utcnow(),
                execution_time_ms=execution_time,
                recommendations=recommendations
            )
            
        except Exception as e:
            execution_time = (time.time() - start_time) * 1000
            return ValidationResult(
                component="workflow_engine",
                test_name="workflow_execution_test",
                status='FAIL',
                score=0.0,
                details=f"Workflow validation failed: {str(e)}",
                timestamp=datetime.utcnow(),
                execution_time_ms=execution_time,
                recommendations=["Check workflow engine connectivity"]
            )
    
    async def _validate_alert_system(self) -> ValidationResult:
        """Validate alerting system functionality"""
        start_time = time.time()
        
        try:
            # Check if performance monitoring is generating alerts
            metrics = await self.performance_monitor.collect_performance_metrics()
            alerts_generated = len([m for m in metrics if m.value >= m.threshold_warning])
            
            # CPU and memory checks
            cpu_percent = psutil.cpu_percent(interval=1)
            memory_percent = psutil.virtual_memory().percent
            
            score = 100.0
            alert_details = []
            
            # Test alert thresholds
            if cpu_percent > 80:
                alert_details.append(f"CPU: {cpu_percent:.1f}%")
            if memory_percent > 80:
                alert_details.append(f"Memory: {memory_percent:.1f}%")
            
            total_alerts = alerts_generated + len(alert_details)
            
            if total_alerts > 0:
                result_status = 'PASS'
                details = f"Alert system active - {total_alerts} alerts detected"
                recommendations = []
            else:
                result_status = 'WARNING'
                details = "No alerts detected - System may be under-monitored"
                recommendations = ["Verify alert thresholds", "Check monitoring coverage"]
                score = 75.0
            
            execution_time = (time.time() - start_time) * 1000
            
            return ValidationResult(
                component="alert_system",
                test_name="alert_system_validation",
                status=result_status,
                score=score,
                details=details,
                timestamp=datetime.utcnow(),
                execution_time_ms=execution_time,
                recommendations=recommendations
            )
            
        except Exception as e:
            execution_time = (time.time() - start_time) * 1000
            return ValidationResult(
                component="alert_system",
                test_name="alert_system_validation",
                status='FAIL',
                score=0.0,
                details=f"Alert validation failed: {str(e)}",
                timestamp=datetime.utcnow(),
                execution_time_ms=execution_time,
                recommendations=["Check alert system configuration"]
            )
    
    async def _validate_data_integrity(self) -> ValidationResult:
        """Validate data integrity across systems"""
        start_time = time.time()
        
        try:
            # Check backup file integrity
            backup_files = list(Path('./backups').glob('*.tar.gz')) if Path('./backups').exists() else []
            
            # Check log file integrity
            log_files = list(Path('./logs').glob('*.log')) if Path('./logs').exists() else []
            
            total_files = len(backup_files) + len(log_files)
            corrupted_files = 0
            
            # Simple integrity check - file readability
            for file_path in backup_files + log_files:
                try:
                    with open(file_path, 'rb') as f:
                        f.read(1024)  # Read first 1KB to test readability
                except:
                    corrupted_files += 1
            
            if total_files == 0:
                result_status = 'WARNING'
                details = "No data files found for integrity check"
                recommendations = ["Generate backup data", "Enable logging"]
                score = 50.0
            elif corrupted_files == 0:
                result_status = 'PASS'
                details = f"Data integrity verified - {total_files} files checked"
                recommendations = []
                score = 100.0
            else:
                result_status = 'FAIL'
                details = f"Data corruption detected - {corrupted_files}/{total_files} files corrupted"
                recommendations = ["Restore from backup", "Check storage system"]
                score = ((total_files - corrupted_files) / total_files) * 100
            
            execution_time = (time.time() - start_time) * 1000
            
            return ValidationResult(
                component="data_integrity",
                test_name="data_integrity_check",
                status=result_status,
                score=score,
                details=details,
                timestamp=datetime.utcnow(),
                execution_time_ms=execution_time,
                recommendations=recommendations
            )
            
        except Exception as e:
            execution_time = (time.time() - start_time) * 1000
            return ValidationResult(
                component="data_integrity",
                test_name="data_integrity_check",
                status='FAIL',
                score=0.0,
                details=f"Integrity validation failed: {str(e)}",
                timestamp=datetime.utcnow(),
                execution_time_ms=execution_time,
                recommendations=["Check file system access"]
            )
    
    async def _calculate_system_health_score(self, validation_results: List[ValidationResult]) -> SystemHealthScore:
        """Calculate overall system health score"""
        if not validation_results:
            return SystemHealthScore(0, 0, 0, 0, 0, 0, datetime.utcnow(), "UNKNOWN")
        
        # Calculate component scores
        total_score = sum(result.score for result in validation_results)
        overall_score = total_score / len(validation_results)
        
        # Component-specific scores
        availability_score = self._get_component_score(validation_results, ["system_health", "workflow_engine"])
        performance_score = self._get_component_score(validation_results, ["performance_monitoring"])
        reliability_score = self._get_component_score(validation_results, ["backup_system", "data_integrity"])
        security_score = self._get_component_score(validation_results, ["security_compliance"])
        compliance_score = security_score  # For now, same as security
        
        # Determine trend
        trend = "STABLE"
        if len(self.health_history) >= 2:
            last_score = self.health_history[-1].overall_score
            if overall_score > last_score + 5:
                trend = "IMPROVING"
            elif overall_score < last_score - 5:
                trend = "DEGRADING"
        
        return SystemHealthScore(
            overall_score=overall_score,
            availability_score=availability_score,
            performance_score=performance_score,
            reliability_score=reliability_score,
            security_score=security_score,
            compliance_score=compliance_score,
            timestamp=datetime.utcnow(),
            trend=trend
        )
    
    def _get_component_score(self, results: List[ValidationResult], components: List[str]) -> float:
        """Get average score for specific components"""
        component_results = [r for r in results if r.component in components]
        if not component_results:
            return 0.0
        return sum(r.score for r in component_results) / len(component_results)
    
    async def _continuous_validation_loop(self):
        """Continuous validation loop"""
        while self.validation_active:
            try:
                # Execute validation every 5 minutes
                await self.execute_production_validation()
                await asyncio.sleep(300)  # 5 minutes
                
            except Exception as e:
                self.logger.error(f"‚ùå Error in validation loop: {e}")
                await asyncio.sleep(300)
    
    async def get_validation_report(self) -> Dict[str, Any]:
        """Generate comprehensive validation report"""
        if not self.validation_results:
            return {"status": "no_data", "message": "No validation data available"}
        
        recent_results = self.validation_results[-8:]  # Last validation run
        current_health = self.health_history[-1] if self.health_history else None
        
        # Calculate pass/fail statistics
        total_tests = len(recent_results)
        passed_tests = len([r for r in recent_results if r.status == 'PASS'])
        failed_tests = len([r for r in recent_results if r.status == 'FAIL'])
        warning_tests = len([r for r in recent_results if r.status == 'WARNING'])
        
        return {
            'timestamp': datetime.utcnow().isoformat(),
            'validation_summary': {
                'total_tests': total_tests,
                'passed': passed_tests,
                'failed': failed_tests,
                'warnings': warning_tests,
                'success_rate': (passed_tests / total_tests * 100) if total_tests > 0 else 0
            },
            'system_health': asdict(current_health) if current_health else None,
            'recent_results': [asdict(r) for r in recent_results],
            'recommendations': self._generate_recommendations(recent_results),
            'validation_active': self.validation_active
        }
    
    def _generate_recommendations(self, results: List[ValidationResult]) -> List[str]:
        """Generate system-wide recommendations"""
        recommendations = set()
        
        failed_components = [r.component for r in results if r.status == 'FAIL']
        warning_components = [r.component for r in results if r.status == 'WARNING']
        
        if 'system_health' in failed_components:
            recommendations.add("CRITICAL: Investigate core system health issues immediately")
        
        if 'backup_system' in failed_components:
            recommendations.add("CRITICAL: Backup system requires immediate attention")
        
        if 'security_compliance' in failed_components:
            recommendations.add("HIGH: Security compliance issues need resolution")
        
        if len(warning_components) > 2:
            recommendations.add("MEDIUM: Multiple systems showing warnings - review system resources")
        
        if not recommendations:
            recommendations.add("System operating within normal parameters")
        
        return list(recommendations)

async def main():
    """Main continuous validation entry point"""
    validator = ContinuousProductionValidator()
    
    try:
        # Initialize validator
        await validator.initialize()
        
        print("\nüîÑ Executing initial production validation...")
        
        # Execute validation
        results = await validator.execute_production_validation()
        
        # Generate report
        report = await validator.get_validation_report()
        
        print(f"\nüìä PRODUCTION VALIDATION RESULTS:")
        print(f"   Total tests: {report['validation_summary']['total_tests']}")
        print(f"   Passed: {report['validation_summary']['passed']}")
        print(f"   Failed: {report['validation_summary']['failed']}")
        print(f"   Warnings: {report['validation_summary']['warnings']}")
        print(f"   Success rate: {report['validation_summary']['success_rate']:.1f}%")
        
        if report['system_health']:
            health = report['system_health']
            print(f"\nüè• SYSTEM HEALTH SCORES:")
            print(f"   Overall: {health['overall_score']:.1f}%")
            print(f"   Availability: {health['availability_score']:.1f}%")
            print(f"   Performance: {health['performance_score']:.1f}%")
            print(f"   Reliability: {health['reliability_score']:.1f}%")
            print(f"   Security: {health['security_score']:.1f}%")
            print(f"   Trend: {health['trend']}")
        
        print(f"\nüí° RECOMMENDATIONS:")
        for rec in report['recommendations'][:3]:
            print(f"   ‚Ä¢ {rec}")
        
        print(f"\nüèÜ CONTINUOUS PRODUCTION VALIDATION OPERATIONAL")
        
        # Continue validation for demonstration
        print("\nüîÑ Continuing validation for 2 minutes...")
        await asyncio.sleep(120)
        
        validator.validation_active = False
        print("‚èπÔ∏è Continuous validation demo complete")
        
    except Exception as e:
        print(f"\n‚ùå Validation system error: {e}")
        validator.validation_active = False

if __name__ == "__main__":
    asyncio.run(main())