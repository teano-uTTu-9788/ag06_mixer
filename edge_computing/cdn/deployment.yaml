apiVersion: v1
kind: ConfigMap
metadata:
  name: ai-mixer-edge-config
  namespace: ai-mixer
data:
  # Cloudflare Worker configuration
  cloudflare-wrangler.toml: |
    name = "ai-mixer-edge"
    main = "workers/cloudflare_worker.js"
    compatibility_date = "2024-08-01"
    compatibility_flags = ["nodejs_compat"]
    
    [env.production]
    name = "ai-mixer-edge-prod"
    route = "api.aimixer.com/*"
    
    [env.staging]
    name = "ai-mixer-edge-staging" 
    route = "api-staging.aimixer.com/*"
    
    # WebAssembly bindings
    [[wasm_modules]]
    binding = "AI_MIXER_WASM"
    source = "./wasm/ai_mixer_wasm.wasm"
    
    # Environment variables
    [vars]
    ENVIRONMENT = "production"
    API_VERSION = "1.0.0"
    MAX_PROCESSING_TIME_MS = "50"
    ENABLE_ANALYTICS = "true"
    
    # Rate limiting
    [rate_limiting]
    requests_per_minute = 1000
    burst_size = 100

  # CDN cache configuration
  cdn-cache.yaml: |
    cache_rules:
      - path: "/wasm/*"
        ttl: 86400  # 24 hours
        edge_ttl: 86400
        browser_ttl: 3600
        
      - path: "/config"
        ttl: 3600   # 1 hour
        edge_ttl: 3600
        browser_ttl: 300
        
      - path: "/health"
        ttl: 60     # 1 minute
        edge_ttl: 60
        browser_ttl: 0
        
      - path: "/stats"
        ttl: 60
        edge_ttl: 60
        browser_ttl: 30
        
      # No caching for processing endpoints
      - path: "/process-audio"
        ttl: 0
        edge_ttl: 0
        browser_ttl: 0
        
      - path: "/extract-features"
        ttl: 0
        edge_ttl: 0
        browser_ttl: 0

---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: ai-mixer-edge-deployer
  namespace: ai-mixer
  labels:
    app: ai-mixer-edge-deployer
spec:
  replicas: 1
  selector:
    matchLabels:
      app: ai-mixer-edge-deployer
  template:
    metadata:
      labels:
        app: ai-mixer-edge-deployer
    spec:
      containers:
      - name: deployer
        image: cloudflare/wrangler:latest
        command: ["/bin/sh"]
        args:
          - -c
          - |
            echo "Starting AI Mixer Edge Deployment"
            
            # Install dependencies
            npm install -g @cloudflare/wrangler
            
            # Deploy to Cloudflare Workers
            wrangler publish --env production
            
            # Deploy WebAssembly modules
            wrangler kv:namespace create "AI_MIXER_CACHE" --env production
            
            # Configure DNS and routing
            curl -X POST "https://api.cloudflare.com/client/v4/zones/${ZONE_ID}/dns_records" \
              -H "Authorization: Bearer ${CF_API_TOKEN}" \
              -H "Content-Type: application/json" \
              --data '{
                "type": "CNAME",
                "name": "api",
                "content": "ai-mixer-edge-prod.workers.dev",
                "proxied": true
              }'
            
            echo "Deployment completed successfully"
            
        env:
        - name: CF_API_TOKEN
          valueFrom:
            secretKeyRef:
              name: cloudflare-credentials
              key: api-token
        - name: ZONE_ID
          valueFrom:
            secretKeyRef:
              name: cloudflare-credentials
              key: zone-id
        volumeMounts:
        - name: config-volume
          mountPath: /app/config
        - name: wasm-volume
          mountPath: /app/wasm
        workingDir: /app
        
      volumes:
      - name: config-volume
        configMap:
          name: ai-mixer-edge-config
      - name: wasm-volume
        emptyDir: {}

---
apiVersion: v1
kind: Secret
metadata:
  name: cloudflare-credentials
  namespace: ai-mixer
type: Opaque
data:
  # Base64 encoded credentials (replace with actual values)
  api-token: # echo -n "your-cf-api-token" | base64
  zone-id: # echo -n "your-zone-id" | base64

---
apiVersion: batch/v1
kind: CronJob
metadata:
  name: ai-mixer-edge-health-check
  namespace: ai-mixer
spec:
  schedule: "*/5 * * * *"  # Every 5 minutes
  jobTemplate:
    spec:
      template:
        spec:
          containers:
          - name: health-checker
            image: curlimages/curl:latest
            command:
              - /bin/sh
              - -c
              - |
                echo "Checking AI Mixer Edge health..."
                
                # Check production endpoint
                RESPONSE=$(curl -s -o /dev/null -w "%{http_code}" https://api.aimixer.com/health)
                if [ "$RESPONSE" -eq 200 ]; then
                  echo "✅ Production endpoint healthy"
                else
                  echo "❌ Production endpoint unhealthy (HTTP $RESPONSE)"
                  exit 1
                fi
                
                # Check WebAssembly availability
                WASM_RESPONSE=$(curl -s -o /dev/null -w "%{http_code}" https://api.aimixer.com/wasm)
                if [ "$WASM_RESPONSE" -eq 200 ]; then
                  echo "✅ WebAssembly module available"
                else
                  echo "❌ WebAssembly module unavailable (HTTP $WASM_RESPONSE)"
                fi
                
                # Test processing endpoint
                curl -s -X POST https://api.aimixer.com/process-audio \
                  -H "Content-Type: application/json" \
                  -d '{"audioBuffer": '$(node -e "console.log(JSON.stringify(Array(960).fill(0.1))))"'}' \
                  > /tmp/response.json
                
                if grep -q "outputBuffer" /tmp/response.json; then
                  echo "✅ Audio processing functional"
                else
                  echo "⚠️ Audio processing may have issues"
                fi
                
                echo "Health check completed"
                
          restartPolicy: OnFailure

---
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: ai-mixer-edge-ingress
  namespace: ai-mixer
  annotations:
    kubernetes.io/ingress.class: "nginx"
    cert-manager.io/cluster-issuer: "letsencrypt-prod"
    nginx.ingress.kubernetes.io/proxy-read-timeout: "30"
    nginx.ingress.kubernetes.io/proxy-body-size: "10m"
    nginx.ingress.kubernetes.io/enable-cors: "true"
    nginx.ingress.kubernetes.io/cors-allow-origin: "*"
    nginx.ingress.kubernetes.io/cors-allow-methods: "GET, POST, OPTIONS"
spec:
  tls:
  - hosts:
    - api.aimixer.com
    - api-staging.aimixer.com
    secretName: ai-mixer-edge-tls
  rules:
  - host: api.aimixer.com
    http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: ai-mixer-edge-service
            port:
              number: 80
  - host: api-staging.aimixer.com
    http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: ai-mixer-edge-staging-service
            port:
              number: 80

---
apiVersion: v1
kind: Service
metadata:
  name: ai-mixer-edge-service
  namespace: ai-mixer
  labels:
    app: ai-mixer-edge
spec:
  type: ClusterIP
  ports:
  - port: 80
    targetPort: 8080
    protocol: TCP
    name: http
  selector:
    app: ai-mixer-edge

---
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  name: ai-mixer-edge-metrics
  namespace: ai-mixer
  labels:
    app: ai-mixer-edge
spec:
  selector:
    matchLabels:
      app: ai-mixer-edge
  endpoints:
  - port: http
    path: /stats
    interval: 30s
    scrapeTimeout: 10s

---
apiVersion: v1
kind: ConfigMap
metadata:
  name: ai-mixer-edge-dashboard
  namespace: ai-mixer
data:
  dashboard.json: |
    {
      "dashboard": {
        "id": null,
        "title": "AI Mixer Edge Computing",
        "tags": ["ai-mixer", "edge", "webassembly"],
        "style": "dark",
        "timezone": "browser",
        "panels": [
          {
            "id": 1,
            "title": "Request Rate",
            "type": "graph",
            "targets": [
              {
                "expr": "sum(rate(http_requests_total{service=\"ai-mixer-edge\"}[5m]))",
                "legendFormat": "Requests/sec"
              }
            ]
          },
          {
            "id": 2,
            "title": "Response Time",
            "type": "graph",
            "targets": [
              {
                "expr": "histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{service=\"ai-mixer-edge\"}[5m])) by (le))",
                "legendFormat": "95th percentile"
              },
              {
                "expr": "histogram_quantile(0.50, sum(rate(http_request_duration_seconds_bucket{service=\"ai-mixer-edge\"}[5m])) by (le))",
                "legendFormat": "50th percentile"
              }
            ]
          },
          {
            "id": 3,
            "title": "Error Rate",
            "type": "stat",
            "targets": [
              {
                "expr": "sum(rate(http_requests_total{service=\"ai-mixer-edge\",status_code!~\"2..\"}[5m])) / sum(rate(http_requests_total{service=\"ai-mixer-edge\"}[5m]))",
                "legendFormat": "Error Rate"
              }
            ]
          },
          {
            "id": 4,
            "title": "Geographic Distribution",
            "type": "worldmap",
            "targets": [
              {
                "expr": "sum by (country) (rate(http_requests_total{service=\"ai-mixer-edge\"}[5m]))",
                "legendFormat": "{{country}}"
              }
            ]
          },
          {
            "id": 5,
            "title": "Processing Time",
            "type": "histogram",
            "targets": [
              {
                "expr": "sum(rate(ai_mixer_processing_duration_seconds_bucket[5m])) by (le)",
                "legendFormat": "Processing time"
              }
            ]
          },
          {
            "id": 6,
            "title": "Genre Distribution",
            "type": "piechart",
            "targets": [
              {
                "expr": "sum by (genre) (rate(ai_mixer_genre_detections_total[5m]))",
                "legendFormat": "{{genre}}"
              }
            ]
          }
        ],
        "time": {
          "from": "now-1h",
          "to": "now"
        },
        "refresh": "30s"
      }
    }