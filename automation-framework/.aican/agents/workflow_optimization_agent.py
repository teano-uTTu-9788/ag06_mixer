#!/usr/bin/env python3
"""
Workflow Optimization Agent
Implements research findings and optimizes AG06 audio processing workflow
"""

import asyncio
import json
import sys
import os
from datetime import datetime
from pathlib import Path
import shutil

class WorkflowOptimizationAgent:
    def __init__(self):
        self.research_data = None
        self.integration_config = None
        
    async def load_research_findings(self):
        """Load research findings from previous agents"""
        print('üìä Loading research findings...')
        
        try:
            with open('../research_findings.json', 'r') as f:
                self.research_data = json.load(f)
            print('‚úÖ Research findings loaded')
        except FileNotFoundError:
            print('‚ùå Research findings not found')
            
        try:
            with open('../ag06_integration_config.json', 'r') as f:
                self.integration_config = json.load(f)
            print('‚úÖ AG06 integration config loaded')
        except FileNotFoundError:
            print('‚ùå AG06 integration config not found')
    
    async def optimize_existing_flask_api(self):
        """Optimize existing Flask API with real audio processing"""
        print('üîß Optimizing existing Flask API...')
        
        # Read current Flask app
        flask_files = [
            'continuous_music_mixer.py',
            'app.py',
            'main.py',
            'server.py'
        ]
        
        current_flask_file = None
        for file in flask_files:
            if os.path.exists(f'../{file}'):
                current_flask_file = file
                break
        
        if not current_flask_file:
            print('‚ùå No Flask application found')
            return False
            
        print(f'üìÅ Found Flask app: {current_flask_file}')
        
        # Create optimized version
        optimized_flask_code = '''#!/usr/bin/env python3
"""
Optimized AG06 Audio Processing Flask API
Integrates real-time audio processing with AG06 hardware
"""

from flask import Flask, jsonify, render_template, request
from flask_socketio import SocketIO, emit
import sounddevice as sd
import numpy as np
from scipy import signal
from collections import deque
import threading
import time
import json
from datetime import datetime

app = Flask(__name__)
app.config['SECRET_KEY'] = 'ag06_audio_key'
socketio = SocketIO(app, cors_allowed_origins="*")

class RealTimeAG06Processor:
    def __init__(self):
        self.is_running = False
        self.sample_rate = 48000
        self.block_size = 256
        self.spectrum_bands = 64
        self.buffer = deque(maxlen=4096)
        
        # Detect AG06 device
        self.device_index = self.detect_ag06_device()
        
        # Initialize frequency bands (64 bands, logarithmic spacing)
        self.freq_bands = np.logspace(np.log10(20), np.log10(20000), self.spectrum_bands)
        
        # Real-time data storage
        self.current_data = {
            'spectrum': [0] * self.spectrum_bands,
            'level_db': -60,
            'classification': 'ambient',
            'peak_frequency': 0,
            'timestamp': time.time()
        }
        
    def detect_ag06_device(self):
        """Detect AG06 audio device"""
        try:
            devices = sd.query_devices()
            for i, device in enumerate(devices):
                device_name = device['name'].lower()
                if 'ag06' in device_name or 'ag03' in device_name or 'yamaha' in device_name:
                    print(f'‚úÖ Found AG06: {device["name"]} (Device {i})')
                    return i
            print('‚ùå AG06 not found, using default input device')
            return None
        except Exception as e:
            print(f'‚ùå Device detection error: {e}')
            return None
    
    def audio_callback(self, indata, frames, time, status):
        """Real-time audio processing callback"""
        if status:
            print(f'Audio status: {status}')
        
        try:
            # Convert to mono
            mono_data = np.mean(indata, axis=1) if indata.shape[1] > 1 else indata[:, 0]
            self.buffer.extend(mono_data)
            
            # Process if buffer has enough data
            if len(self.buffer) >= self.block_size:
                self.process_audio_block()
                
        except Exception as e:
            print(f'Audio callback error: {e}')
    
    def process_audio_block(self):
        """Process audio block with spectrum analysis"""
        try:
            # Get latest block from buffer
            audio_block = np.array(list(self.buffer)[-self.block_size:])
            
            # Apply Hann window (Google best practice)
            windowed = audio_block * signal.windows.hann(len(audio_block))
            
            # FFT analysis
            fft = np.fft.fft(windowed, n=2048)
            magnitude = np.abs(fft[:1024])
            
            # Convert to frequency bands
            freqs = np.fft.fftfreq(2048, 1/self.sample_rate)[:1024]
            band_values = []
            
            for i in range(self.spectrum_bands):
                if i < len(self.freq_bands) - 1:
                    band_mask = (freqs >= self.freq_bands[i]) & (freqs < self.freq_bands[i+1])
                    band_energy = np.sum(magnitude[band_mask]) if np.any(band_mask) else 0
                    band_values.append(band_energy)
                else:
                    band_values.append(0)
            
            # Normalize to 0-100 range
            if max(band_values) > 0:
                normalized_bands = [(val/max(band_values)) * 100 for val in band_values]
            else:
                normalized_bands = [0] * self.spectrum_bands
            
            # Find peak frequency
            peak_idx = np.argmax(magnitude)
            peak_freq = freqs[peak_idx] if peak_idx < len(freqs) else 0
            
            # Music vs Voice classification (Spotify-inspired algorithm)
            low_freq_energy = sum(normalized_bands[:8])     # 20-200 Hz (bass)
            mid_freq_energy = sum(normalized_bands[8:32])   # 200-2000 Hz (vocals)
            high_freq_energy = sum(normalized_bands[32:])   # 2000+ Hz (harmonics)
            
            # Classification logic
            total_energy = sum(normalized_bands)
            if total_energy < 1:
                classification = 'silent'
            elif mid_freq_energy > max(low_freq_energy, high_freq_energy) and 80 <= peak_freq <= 300:
                classification = 'voice'
            elif high_freq_energy > 20 and total_energy > 10:
                classification = 'music'
            else:
                classification = 'ambient'
            
            # Calculate RMS level in dB
            rms_level = np.sqrt(np.mean(audio_block**2))
            level_db = 20 * np.log10(max(rms_level, 1e-10)) + 60  # Adjust for display
            level_db = max(-60, min(level_db, 0))  # Clamp to -60dB to 0dB range
            
            # Update current data
            self.current_data = {
                'spectrum': normalized_bands,
                'level_db': level_db,
                'classification': classification,
                'peak_frequency': abs(peak_freq),
                'timestamp': time.time()
            }
            
            # Emit real-time data via WebSocket
            socketio.emit('audio_data', self.current_data)
            
        except Exception as e:
            print(f'Processing error: {e}')
    
    def start_monitoring(self):
        """Start real-time audio monitoring"""
        if self.is_running:
            return
            
        try:
            self.stream = sd.InputStream(
                device=self.device_index,
                channels=2,
                samplerate=self.sample_rate,
                blocksize=self.block_size,
                callback=self.audio_callback
            )
            
            self.stream.start()
            self.is_running = True
            print('‚úÖ Real-time audio monitoring started')
            
        except Exception as e:
            print(f'‚ùå Failed to start audio monitoring: {e}')
    
    def stop_monitoring(self):
        """Stop audio monitoring"""
        if hasattr(self, 'stream') and self.is_running:
            self.stream.stop()
            self.stream.close()
            self.is_running = False
            print('‚úÖ Audio monitoring stopped')

# Initialize global processor
processor = RealTimeAG06Processor()

@app.route('/')
def index():
    """Main dashboard"""
    return render_template('index.html')

@app.route('/api/spectrum')
def get_spectrum():
    """Get current spectrum data"""
    return jsonify(processor.current_data)

@app.route('/api/start')
def start_monitoring():
    """Start audio monitoring"""
    processor.start_monitoring()
    return jsonify({'status': 'started', 'message': 'Real-time monitoring active'})

@app.route('/api/stop')
def stop_monitoring():
    """Stop audio monitoring"""
    processor.stop_monitoring()
    return jsonify({'status': 'stopped', 'message': 'Monitoring stopped'})

@app.route('/api/status')
def get_status():
    """Get system status"""
    return jsonify({
        'monitoring': processor.is_running,
        'device_detected': processor.device_index is not None,
        'sample_rate': processor.sample_rate,
        'bands': processor.spectrum_bands,
        'timestamp': datetime.now().isoformat()
    })

@socketio.on('connect')
def handle_connect():
    """Handle WebSocket connection"""
    print('Client connected to real-time audio stream')
    emit('status', {'message': 'Connected to AG06 real-time processor'})

@socketio.on('disconnect')
def handle_disconnect():
    """Handle WebSocket disconnection"""
    print('Client disconnected from real-time audio stream')

if __name__ == '__main__':
    print('üéõÔ∏è OPTIMIZED AG06 AUDIO PROCESSOR STARTING')
    print('=' * 50)
    
    # Auto-start monitoring
    processor.start_monitoring()
    
    # Start Flask app
    socketio.run(app, host='0.0.0.0', port=8080, debug=False)
'''
        
        # Save optimized Flask app
        with open('../optimized_ag06_flask_app.py', 'w') as f:
            f.write(optimized_flask_code)
        
        print('‚úÖ Optimized Flask API created')
        return True
    
    async def create_enhanced_html_template(self):
        """Create enhanced HTML template with real-time updates"""
        print('üé® Creating enhanced HTML template...')
        
        html_template = '''<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AG06 Real-Time Audio Processor</title>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/socket.io/4.5.2/socket.io.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/Chart.js/3.9.1/chart.min.js"></script>
    <style>
        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            margin: 0;
            padding: 20px;
            background: linear-gradient(135deg, #1e3c72, #2a5298);
            color: white;
            min-height: 100vh;
        }
        
        .container {
            max-width: 1200px;
            margin: 0 auto;
        }
        
        .header {
            text-align: center;
            margin-bottom: 30px;
        }
        
        .header h1 {
            font-size: 2.5rem;
            margin: 0;
            text-shadow: 2px 2px 4px rgba(0,0,0,0.3);
        }
        
        .status-panel {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));
            gap: 20px;
            margin-bottom: 30px;
        }
        
        .status-card {
            background: rgba(255,255,255,0.1);
            padding: 20px;
            border-radius: 10px;
            backdrop-filter: blur(10px);
            border: 1px solid rgba(255,255,255,0.2);
        }
        
        .spectrum-container {
            background: rgba(0,0,0,0.2);
            padding: 20px;
            border-radius: 10px;
            margin-bottom: 20px;
        }
        
        .spectrum-bars {
            display: flex;
            align-items: end;
            height: 200px;
            gap: 2px;
            padding: 10px 0;
        }
        
        .spectrum-bar {
            background: linear-gradient(to top, #ff6b6b, #4ecdc4, #45b7d1);
            min-width: 8px;
            border-radius: 2px 2px 0 0;
            transition: height 0.1s ease;
        }
        
        .controls {
            text-align: center;
            margin: 20px 0;
        }
        
        .btn {
            background: #4CAF50;
            color: white;
            border: none;
            padding: 12px 24px;
            margin: 0 10px;
            border-radius: 25px;
            cursor: pointer;
            font-size: 16px;
            transition: all 0.3s ease;
        }
        
        .btn:hover {
            transform: translateY(-2px);
            box-shadow: 0 4px 15px rgba(0,0,0,0.3);
        }
        
        .btn.stop {
            background: #f44336;
        }
        
        .classification-indicator {
            font-size: 1.5rem;
            font-weight: bold;
            padding: 10px 20px;
            border-radius: 25px;
            display: inline-block;
            margin: 10px 0;
        }
        
        .voice { background: #2196F3; }
        .music { background: #FF9800; }
        .ambient { background: #9C27B0; }
        .silent { background: #607D8B; }
        
        .level-meter {
            width: 100%;
            height: 20px;
            background: #333;
            border-radius: 10px;
            overflow: hidden;
            margin: 10px 0;
        }
        
        .level-fill {
            height: 100%;
            background: linear-gradient(to right, #4CAF50, #FFEB3B, #FF5722);
            transition: width 0.2s ease;
            border-radius: 10px;
        }
    </style>
</head>
<body>
    <div class="container">
        <div class="header">
            <h1>üéõÔ∏è AG06 Real-Time Audio Processor</h1>
            <p>Advanced audio analysis with industry best practices</p>
        </div>
        
        <div class="status-panel">
            <div class="status-card">
                <h3>System Status</h3>
                <div id="connectionStatus">Connecting...</div>
                <div id="deviceStatus">Detecting device...</div>
            </div>
            
            <div class="status-card">
                <h3>Audio Level</h3>
                <div class="level-meter">
                    <div class="level-fill" id="levelMeter"></div>
                </div>
                <div id="levelValue">-60 dB</div>
            </div>
            
            <div class="status-card">
                <h3>Classification</h3>
                <div class="classification-indicator ambient" id="classification">
                    AMBIENT
                </div>
            </div>
            
            <div class="status-card">
                <h3>Peak Frequency</h3>
                <div id="peakFrequency">0 Hz</div>
            </div>
        </div>
        
        <div class="spectrum-container">
            <h3>64-Band Spectrum Analyzer</h3>
            <div class="spectrum-bars" id="spectrumBars">
                <!-- Spectrum bars will be generated by JavaScript -->
            </div>
        </div>
        
        <div class="controls">
            <button class="btn" onclick="startMonitoring()">‚ñ∂Ô∏è Start Monitoring</button>
            <button class="btn stop" onclick="stopMonitoring()">‚èπÔ∏è Stop Monitoring</button>
        </div>
    </div>

    <script>
        // Initialize WebSocket connection
        const socket = io();
        
        // Generate spectrum bars
        function initializeSpectrumBars() {
            const container = document.getElementById('spectrumBars');
            for (let i = 0; i < 64; i++) {
                const bar = document.createElement('div');
                bar.className = 'spectrum-bar';
                bar.style.height = '1px';
                container.appendChild(bar);
            }
        }
        
        // Update spectrum visualization
        function updateSpectrum(data) {
            const bars = document.querySelectorAll('.spectrum-bar');
            data.spectrum.forEach((value, index) => {
                if (bars[index]) {
                    const height = Math.max(1, (value / 100) * 200);
                    bars[index].style.height = height + 'px';
                }
            });
        }
        
        // Update UI elements
        function updateUI(data) {
            // Level meter
            const levelMeter = document.getElementById('levelMeter');
            const levelValue = document.getElementById('levelValue');
            const levelPercent = Math.max(0, Math.min(100, ((data.level_db + 60) / 60) * 100));
            levelMeter.style.width = levelPercent + '%';
            levelValue.textContent = data.level_db.toFixed(1) + ' dB';
            
            // Classification
            const classification = document.getElementById('classification');
            classification.textContent = data.classification.toUpperCase();
            classification.className = 'classification-indicator ' + data.classification;
            
            // Peak frequency
            document.getElementById('peakFrequency').textContent = 
                data.peak_frequency.toFixed(1) + ' Hz';
        }
        
        // Socket event handlers
        socket.on('connect', () => {
            document.getElementById('connectionStatus').textContent = '‚úÖ Connected';
        });
        
        socket.on('disconnect', () => {
            document.getElementById('connectionStatus').textContent = '‚ùå Disconnected';
        });
        
        socket.on('audio_data', (data) => {
            updateSpectrum(data);
            updateUI(data);
        });
        
        socket.on('status', (data) => {
            console.log('Status:', data.message);
        });
        
        // Control functions
        function startMonitoring() {
            fetch('/api/start')
                .then(response => response.json())
                .then(data => console.log('Monitoring started:', data));
        }
        
        function stopMonitoring() {
            fetch('/api/stop')
                .then(response => response.json())
                .then(data => console.log('Monitoring stopped:', data));
        }
        
        // Initialize on page load
        document.addEventListener('DOMContentLoaded', () => {
            initializeSpectrumBars();
            
            // Check system status
            fetch('/api/status')
                .then(response => response.json())
                .then(data => {
                    document.getElementById('deviceStatus').textContent = 
                        data.device_detected ? '‚úÖ AG06 Detected' : '‚ùå No AG06 Found';
                });
        });
    </script>
</body>
</html>'''
        
        # Create templates directory and save
        os.makedirs('../templates', exist_ok=True)
        with open('../templates/index.html', 'w') as f:
            f.write(html_template)
        
        print('‚úÖ Enhanced HTML template created')
        return True
    
    async def generate_deployment_script(self):
        """Generate deployment script for the optimized system"""
        print('üöÄ Generating deployment script...')
        
        deployment_script = '''#!/bin/bash
# AG06 Audio Processor Deployment Script
# Optimized workflow implementation

echo "üéõÔ∏è AG06 AUDIO PROCESSOR DEPLOYMENT"
echo "================================="

# Check Python version
python_version=$(python3 --version 2>&1)
echo "Python version: $python_version"

# Install required packages
echo "üì¶ Installing required packages..."
pip3 install flask flask-socketio sounddevice numpy scipy librosa aubio pyaudio

# Install system dependencies (macOS)
if [[ "$OSTYPE" == "darwin"* ]]; then
    echo "üçé Installing macOS audio dependencies..."
    brew install portaudio sox
    pip3 install pyobjc-core pyobjc-framework-CoreAudio
fi

# Create necessary directories
mkdir -p templates static logs

# Set permissions
chmod +x optimized_ag06_flask_app.py

# Check AG06 device
echo "üîç Checking for AG06 device..."
python3 -c "
import sounddevice as sd
devices = sd.query_devices()
ag06_found = False
for i, device in enumerate(devices):
    if 'ag06' in device['name'].lower() or 'ag03' in device['name'].lower():
        print(f'‚úÖ Found AG06: {device[\"name\"]} (Device {i})')
        ag06_found = True
        break
if not ag06_found:
    print('‚ùå AG06 device not found')
    print('Available input devices:')
    for i, device in enumerate(devices):
        if device['max_input_channels'] > 0:
            print(f'  {i}: {device[\"name\"]}')
"

echo "üöÄ Starting AG06 Audio Processor..."
python3 optimized_ag06_flask_app.py
'''
        
        with open('../deploy_ag06_processor.sh', 'w') as f:
            f.write(deployment_script)
        
        # Make executable
        os.chmod('../deploy_ag06_processor.sh', 0o755)
        
        print('‚úÖ Deployment script created')
        return True

    async def generate_integration_report(self):
        """Generate comprehensive integration report"""
        report = {
            'timestamp': datetime.now().isoformat(),
            'optimization_summary': {
                'research_sources': ['Google', 'Meta', 'Spotify', 'Apple', 'Adobe'],
                'key_improvements': [
                    'Real-time AG06 hardware integration',
                    'Industry-standard FFT processing with Hann windowing',
                    '64-band logarithmic frequency analysis',
                    'WebSocket real-time data streaming',
                    'Advanced music vs voice classification',
                    'Professional-grade level metering'
                ],
                'files_created': [
                    'optimized_ag06_flask_app.py',
                    'templates/index.html',
                    'deploy_ag06_processor.sh'
                ]
            },
            'technical_specifications': {
                'sample_rate': 48000,
                'bit_depth': 24,
                'buffer_size': 256,
                'spectrum_bands': 64,
                'latency_target': '<10ms',
                'frequency_range': '20Hz - 20kHz'
            },
            'next_steps': [
                'Test with actual AG06 hardware',
                'Fine-tune classification algorithms',
                'Add recording capabilities',
                'Implement preset management',
                'Add MIDI integration for mixer control'
            ]
        }
        
        with open('../workflow_optimization_report.json', 'w') as f:
            json.dump(report, f, indent=2)
        
        return report

async def main():
    agent = WorkflowOptimizationAgent()
    
    print('üîß WORKFLOW OPTIMIZATION AGENT DEPLOYED')
    print('=' * 45)
    
    # Load research findings
    await agent.load_research_findings()
    
    # Optimize Flask API
    await agent.optimize_existing_flask_api()
    
    # Create enhanced template
    await agent.create_enhanced_html_template()
    
    # Generate deployment script
    await agent.generate_deployment_script()
    
    # Generate integration report
    report = await agent.generate_integration_report()
    
    print('\n‚úÖ WORKFLOW OPTIMIZATION COMPLETE')
    print('=' * 45)
    print('üìÅ Generated Files:')
    print('  ‚Ä¢ optimized_ag06_flask_app.py - Main application')
    print('  ‚Ä¢ templates/index.html - Enhanced web interface')
    print('  ‚Ä¢ deploy_ag06_processor.sh - Deployment script')
    print('  ‚Ä¢ workflow_optimization_report.json - Integration report')
    
    print('\nüöÄ DEPLOYMENT INSTRUCTIONS:')
    print('1. Run: chmod +x deploy_ag06_processor.sh')
    print('2. Run: ./deploy_ag06_processor.sh')
    print('3. Open: http://localhost:8080')
    print('4. Connect AG06 and start monitoring')
    
    return report

if __name__ == '__main__':
    asyncio.run(main())