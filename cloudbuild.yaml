# Google Cloud Build configuration
# Following Google's internal CI/CD best practices
timeout: 1800s
options:
  machineType: 'E2_HIGHCPU_8'
  logging: CLOUD_LOGGING_ONLY
  pool:
    name: 'projects/$PROJECT_ID/locations/us-central1/workerPools/audio-mixer-pool'

# Substitutions for environment-specific values
substitutions:
  _REGION: us-central1
  _GKE_CLUSTER: audio-mixer-cluster
  _NAMESPACE: ag06-mixer
  _SERVICE_NAME: audio-processing
  _DEPLOYMENT_PERCENTAGE: "10"  # Canary percentage

# Build steps
steps:
# Step 1: Run unit tests
- name: 'python:3.11-slim'
  id: 'unit-tests'
  entrypoint: 'bash'
  args:
  - '-c'
  - |
    pip install -r requirements.txt
    python -m pytest tests/ \
      --cov=. \
      --cov-report=xml \
      --cov-report=term \
      --junitxml=test-results.xml \
      -v
  env:
  - 'PYTHONPATH=/workspace'

# Step 2: Static analysis and linting
- name: 'python:3.11-slim'
  id: 'static-analysis'
  entrypoint: 'bash'
  args:
  - '-c'
  - |
    pip install pylint black isort mypy bandit safety
    black --check .
    isort --check-only .
    pylint **/*.py --exit-zero
    mypy . --ignore-missing-imports
    bandit -r . -ll
    safety check
  waitFor: ['-']  # Run in parallel

# Step 3: Build container image
- name: 'gcr.io/kaniko-project/executor:latest'
  id: 'build-image'
  args:
  - --destination=gcr.io/$PROJECT_ID/${_SERVICE_NAME}:${SHORT_SHA}
  - --destination=gcr.io/$PROJECT_ID/${_SERVICE_NAME}:latest
  - --cache=true
  - --cache-ttl=24h
  - --build-arg=VERSION=${SHORT_SHA}
  waitFor: ['unit-tests']

# Step 4: Vulnerability scanning
- name: 'gcr.io/cloud-builders/gcloud'
  id: 'vulnerability-scan'
  args:
  - 'container'
  - 'images'
  - 'scan'
  - 'gcr.io/$PROJECT_ID/${_SERVICE_NAME}:${SHORT_SHA}'
  - '--remote'
  waitFor: ['build-image']

# Step 5: Integration tests
- name: 'gcr.io/$PROJECT_ID/${_SERVICE_NAME}:${SHORT_SHA}'
  id: 'integration-tests'
  entrypoint: 'bash'
  args:
  - '-c'
  - |
    # Start service in background
    python microservices/audio_service.py &
    SERVICE_PID=$!
    
    # Wait for service to be ready
    for i in {1..30}; do
      if curl -f http://localhost:8080/health; then
        break
      fi
      sleep 1
    done
    
    # Run integration tests
    python -m pytest tests/integration/ -v
    
    # Stop service
    kill $SERVICE_PID
  waitFor: ['build-image']

# Step 6: Performance tests
- name: 'grafana/k6'
  id: 'performance-tests'
  entrypoint: 'k6'
  args:
  - 'run'
  - '--vus=10'
  - '--duration=30s'
  - '--out=cloud'
  - 'tests/performance/load_test.js'
  env:
  - 'K6_CLOUD_TOKEN=${_K6_TOKEN}'
  waitFor: ['integration-tests']

# Step 7: Deploy to staging (canary)
- name: 'gcr.io/cloud-builders/kubectl'
  id: 'deploy-canary'
  args:
  - 'set'
  - 'image'
  - 'deployment/${_SERVICE_NAME}-canary'
  - '${_SERVICE_NAME}=gcr.io/$PROJECT_ID/${_SERVICE_NAME}:${SHORT_SHA}'
  - '--namespace=${_NAMESPACE}'
  env:
  - 'CLOUDSDK_COMPUTE_REGION=${_REGION}'
  - 'CLOUDSDK_CONTAINER_CLUSTER=${_GKE_CLUSTER}'
  waitFor: ['performance-tests']

# Step 8: Smoke tests on canary
- name: 'gcr.io/cloud-builders/gcloud'
  id: 'smoke-tests'
  entrypoint: 'bash'
  args:
  - '-c'
  - |
    # Wait for rollout to complete
    kubectl rollout status deployment/${_SERVICE_NAME}-canary -n ${_NAMESPACE}
    
    # Get canary endpoint
    CANARY_IP=$(kubectl get service ${_SERVICE_NAME}-canary -n ${_NAMESPACE} -o jsonpath='{.status.loadBalancer.ingress[0].ip}')
    
    # Run smoke tests
    for i in {1..10}; do
      response=$(curl -s -o /dev/null -w "%{http_code}" http://$CANARY_IP:50051/health)
      if [ "$response" != "200" ]; then
        echo "Smoke test failed with response code: $response"
        exit 1
      fi
      sleep 1
    done
  waitFor: ['deploy-canary']

# Step 9: Progressive rollout
- name: 'gcr.io/cloud-builders/gcloud'
  id: 'progressive-rollout'
  entrypoint: 'bash'
  args:
  - '-c'
  - |
    # Update Istio VirtualService for traffic splitting
    cat <<EOF | kubectl apply -f -
    apiVersion: networking.istio.io/v1beta1
    kind: VirtualService
    metadata:
      name: ${_SERVICE_NAME}
      namespace: ${_NAMESPACE}
    spec:
      hosts:
      - ${_SERVICE_NAME}
      http:
      - route:
        - destination:
            host: ${_SERVICE_NAME}
            subset: stable
          weight: $((100 - ${_DEPLOYMENT_PERCENTAGE}))
        - destination:
            host: ${_SERVICE_NAME}
            subset: canary
          weight: ${_DEPLOYMENT_PERCENTAGE}
    EOF
    
    # Monitor metrics for 5 minutes
    sleep 300
    
    # Check error rate
    ERROR_RATE=$(kubectl exec -n istio-system deployment/prometheus -- \
      promtool query instant 'rate(istio_request_duration_milliseconds_count{destination_service_name="${_SERVICE_NAME}",response_code=~"5.."}[5m])')
    
    if (( $(echo "$ERROR_RATE > 0.01" | bc -l) )); then
      echo "Error rate too high: $ERROR_RATE"
      exit 1
    fi
  waitFor: ['smoke-tests']

# Step 10: Full deployment (if canary succeeds)
- name: 'gcr.io/cloud-builders/kubectl'
  id: 'full-deployment'
  args:
  - 'set'
  - 'image'
  - 'deployment/${_SERVICE_NAME}'
  - '${_SERVICE_NAME}=gcr.io/$PROJECT_ID/${_SERVICE_NAME}:${SHORT_SHA}'
  - '--namespace=${_NAMESPACE}'
  env:
  - 'CLOUDSDK_COMPUTE_REGION=${_REGION}'
  - 'CLOUDSDK_CONTAINER_CLUSTER=${_GKE_CLUSTER}'
  waitFor: ['progressive-rollout']

# Step 11: Update monitoring dashboards
- name: 'gcr.io/cloud-builders/gcloud'
  id: 'update-dashboards'
  entrypoint: 'bash'
  args:
  - '-c'
  - |
    # Update Grafana dashboards with new version
    curl -X POST https://grafana.example.com/api/dashboards/db \
      -H "Authorization: Bearer ${_GRAFANA_TOKEN}" \
      -H "Content-Type: application/json" \
      -d @monitoring/dashboards/audio-processing.json
    
    # Create deployment annotation
    curl -X POST https://grafana.example.com/api/annotations \
      -H "Authorization: Bearer ${_GRAFANA_TOKEN}" \
      -H "Content-Type: application/json" \
      -d '{
        "dashboardId": 1,
        "text": "Deployed version ${SHORT_SHA}",
        "tags": ["deployment", "${_SERVICE_NAME}"]
      }'
  waitFor: ['full-deployment']

# Artifacts to store
artifacts:
  objects:
    location: 'gs://${PROJECT_ID}_artifacts/${_SERVICE_NAME}/${SHORT_SHA}'
    paths:
    - 'test-results.xml'
    - 'coverage.xml'
    - 'performance-results.json'

# Build notifications
availableSecrets:
  secretManager:
  - versionName: projects/${PROJECT_ID}/secrets/k6-token/versions/latest
    env: '_K6_TOKEN'
  - versionName: projects/${PROJECT_ID}/secrets/grafana-token/versions/latest
    env: '_GRAFANA_TOKEN'

# Error handling
options:
  logging: CLOUD_LOGGING_ONLY
  logStreamingOption: STREAM_ON
  substitutionOption: 'ALLOW_LOOSE'
  
# Rollback on failure
- name: 'gcr.io/cloud-builders/kubectl'
  id: 'rollback'
  entrypoint: 'bash'
  args:
  - '-c'
  - |
    echo "Deployment failed, rolling back..."
    kubectl rollout undo deployment/${_SERVICE_NAME} -n ${_NAMESPACE}
    kubectl rollout undo deployment/${_SERVICE_NAME}-canary -n ${_NAMESPACE}
    
    # Reset traffic splitting
    kubectl patch virtualservice ${_SERVICE_NAME} -n ${_NAMESPACE} \
      --type merge \
      -p '{"spec":{"http":[{"route":[{"destination":{"host":"${_SERVICE_NAME}","subset":"stable"},"weight":100}]}]}}'
  waitFor: ['-']  # Always run on failure
  allowFailure: true
  allowExit: true